這個目錄是:https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E7%9A%84%E7%B5%B1%E8%A8%88%E5%9F%BA%E7%A4%8E-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E8%83%8C%E5%BE%8C%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E8%A1%93-530caf5ea795
其餘內容大部份由ChatGPT產生

第 1 章 機器與深度學習常用的數學基礎
第 2 章 機器學習相關機率論
第 3 章 機器學習常用的統計學(一)
統計學基礎概念介紹：母體、樣本、變量、參數、統計量、標準差等
3.1 統計學基礎概念
3.2 機率分佈
3.3 抽樣與估計
3.4 假設檢定
3.5 方差分析
3.6 簡單線性迴歸
3.7 多元迴歸
3.8 標準差及其應用


標準差（standard deviation）是一種測量資料變異程度的數值，用來衡量資料集合中各資料點與平均數之間的距離。
https://www.newton.com.tw/wiki/%E6%A8%99%E6%BA%96%E5%B7%AE

在統計學中，標準差是常用的一個統計量，可以用於刻畫一個資料集的分布情況，
也就是用來衡量數據中的差異程度。
Standard deviation is a measure of the degree of variation between values in a dataset.
s = sqrt( (1/n) * sum(xi - x)^2)
其中，s代表標準差，n代表資料的個數，xi代表第i個資料點，x代表所有資料點的平均數。

標準差的計算公式中，要先計算每個數據點與平均值之差的平方，這是為了消除正負號的影響，
並且強化離群值對標準差的影響。平方後再將這些差的平方值加總，然後求其平均數，這個平均值就是樣本方差。
最後，再將樣本方差取平方根就得到了標準差。

例如，兩組數的集合
G1={0,5,9,14}
G2={5,6,8,9}
其平均值都是7，
但第G2具有較小的標準差。

for G1,
先算所有數值差的平方
(0-7)^2=49
(5-7)^2=4
(9-7)^=4
(14-7)^=49
再取平均26.5
再開根號就是標準差sigma=5.14781507049

如是總體（即估算總體方差），根號內除以n（對應excel函式：STDEVP）；
如是抽樣（即估算樣本方差），根號內除以（n-1）（對應excel函式：STDEV）；
因為我們大量接觸的是樣本，所以普遍使用根號內除以（n-1）。

使用平方的原因是為了消除正負號的影響。如果只是將差值相加，正值和負值會互相抵消，
這樣計算出來的數值可能並不反映數據的真實變異程度。而平方可以將正值和負值都變成正值，
這樣就能更好地反映數據的變異情況。

最後再將樣本方差取平方根，是為了回復數據的原始尺度，使其易於理解和比較。
例如，如果樣本是身高，那麼計算出來的標準差也是以身高的單位來表示，這樣就可以用標準差來衡量數據中身高的差異程度。



這一段直接抄
https://www.newton.com.tw/wiki/%E6%A8%99%E6%BA%96%E5%B7%AE

一組數據怎樣去評價和量化它的離散度，有很多種方法：
極差 (極值)
最直接也是最簡單的方法，即最大值－最小值（也就是極差）來評價一組數據的離散度。這一方法在日常生活中最為常見，
比如比賽中去掉最高最低分就是極差的具體套用。

離均差平方和
由於誤差的不可控性，因此只由兩個數據來評判一組數據是不科學的。所以人們在要求更高的領域不使用極差來評判。其實，
離散度就是數據偏離平均值的程度。因此將數據與均值之差（我們叫它離均差）加起來就能反映出一個準確的離散程度。和越大離散度也就越大。
但是由於偶然誤差是成常態分配的，離均差有正有負，對於大樣本離均差的代數和為零的。為了避免正負問題，
在數學有上有兩種方法：一種是取絕對值，也就是常說的離均差絕對值之和。而為了避免符號問題，
數學上最常用的是另一種方法－－平方，這樣就都成了非負數。因此，離均差的平方和成了評價離散度一個指標。

方差
由於離均差的平方和與樣本個數有關，只能反映相同樣本的離散度，而實際工作中做比較很難做到相同的樣本，
因此為了消除樣本個數的影響，增加可比性，將離均差的平方和求平均值，這就是我們所說的方差成了評價離散度的較好指標。
樣本量越大越能反映真實的情況，而算術平均值卻完全忽略了這個問題，對此統計學上早有考慮，
在統計學中樣本的均差多是除以自由度（n-1），它的意思是樣本能自由選擇的程度。當選到只剩一個時，它不可能再有自由了，所以自由度是n-1。

標準差意義
由於方差是數據的平方，與檢測值本身相差太大，人們難以直觀的衡量，所以常用方差開根號換算回來這就是我們要說的標準差。
在統計學中樣本的均差多是除以自由度（n-1），它是意思是樣本能自由選擇的程度。當選到只剩一個時，它不可能再有自由了，所以自由度是n-1。

變異係數
標準差能很客觀準確的反映一組數據的離散程度，但是對於不同的項目，或同一項目不同的樣本，標準差就缺乏可比性了，
因此對於方法學評價來說又引入了變異係數CV。
一組數據的平均值及標準差常常同時做為參考的依據。在直覺上，如果數值的中心以平均值來考慮，
則標準差為統計分布之一“自然”的測量。
定義公式：其中N應為n-1，即自由度
標準差與平均值定義公式
標準差與平均值定義公式
⒈方差s^2=[（x1-x）^2+（x2-x）^2+......（xn-x）^2]/（n）（x為平均數）
⒉標準差=方差的算術平方根errorbar。在實驗中單次測量總是難免會產生誤差，為此我們經常測量多次，
然後用測量值的平均值表示測量的量，並用誤差條來表征數據的分布，其中誤差條的高度為±標準誤。這裡即標準差。

常見的統計分布：常態分布、t分布、卡方分布、F分布等
統計推論：點估計、區間估計、假設檢定等
簡單線性迴歸：迴歸分析的基本概念、最小二乘法、評估迴歸模型等
多元線性迴歸：多元迴歸模型、變數選擇、多重共線性等
方差分析：單因素方差分析、多因素方差分析、變異數分析等
相關分析：皮爾遜相關分析、斯皮爾曼相關分析、克拉默相關分析等
非參數統計方法：核密度估計、K最近鄰法、決策樹等

第 4 章 機器學習常用的統計學(二)
第 5 章 機器學習常用的資料處理方式
第 6 章 機器與深度學習常用到的基礎理論
第 7 章 迴歸分析Regression
第 8 章 分類Classification
第 9 章 統計降維法Dimension Reduction
第 10 章 類神經網路Artificial Neural Network
第 11 章 梯度下降法Gradient Descent
第 12 章 倒傳遞學習法Backpropagation
第 13 章 參數常規化 Parameter Regularization
第 14 章 模型評估Model Validation
